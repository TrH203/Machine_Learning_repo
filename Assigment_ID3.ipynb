{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iVBmYb5tkV7f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ_qxuQ_hL7U"
      },
      "source": [
        "1. Viết code đọc file weather.csv. Hiện kết quả kiểm tra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uucJfYCCkV7q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([['sunny', 'hot', 'high', 'weak', 'no'],\n",
              "        ['sunny', 'hot', 'high', 'strong', 'no'],\n",
              "        ['overcast', 'hot', 'high', 'weak', 'yes'],\n",
              "        ['rainy', 'mild', 'high', 'weak', 'yes'],\n",
              "        ['rainy', 'cool', 'normal', 'weak', 'yes'],\n",
              "        ['rainy', 'cool', 'normal', 'strong', 'no'],\n",
              "        ['overcast', 'cool', 'normal', 'strong', 'yes'],\n",
              "        ['sunny', 'mild', 'high', 'weak', 'no'],\n",
              "        ['sunny', 'cool', 'normal', 'weak', 'yes'],\n",
              "        ['rainy', 'mild', 'normal', 'weak', 'yes'],\n",
              "        ['sunny', 'mild', 'normal', 'strong', 'yes'],\n",
              "        ['overcast', 'mild', 'high', 'strong', 'yes'],\n",
              "        ['overcast', 'hot', 'normal', 'weak', 'yes'],\n",
              "        ['rainy', 'mild', 'high', 'strong', 'no']], dtype=object),\n",
              " Index(['outlook', 'temperature', 'humidity', 'wind', 'class'], dtype='object'),\n",
              " array([0, 1, 2, 3, 4]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('weather1.csv')\n",
        "col = df.columns\n",
        "\n",
        "df = df.values\n",
        "col_index = np.arange(len(col))\n",
        "df, col,col_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeC4uCj2hpge"
      },
      "source": [
        "2. Cho list sau\n",
        "list1=[\"co\",\"co\",\"co\",\"khong\",\"khong\",\"khong\",\"khong\"]\n",
        "Cho biết có bao nhiêu loại thông tin và số lần xuất hiện của nó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUSyCSYgkV7r",
        "outputId": "6348dc42-84b4-455e-c795-6992426dbcdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['co', 'khong'], dtype='<U5')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list1=[\"co\",\"co\",\"co\",\"khong\",\"khong\",\"khong\",\"khong\"]\n",
        "np.unique(list1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0zvmtx9h1Fa"
      },
      "source": [
        "3. Viết câu lệnh để sinh dữ liệu cho mảng từ vòng lặp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWjKmTNdhoTs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RwGAC_dQ5uj",
        "outputId": "4e2ab239-93b8-4b34-f667-6904a9cc1347"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[i for i in range(0,7)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aOeZ0LYiAnx"
      },
      "source": [
        "4. In dữ liệu của cột nhãn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5RJrAO3kV7u",
        "outputId": "c3fc3008-23d4-4701-a91c-3cd258879db2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes',\n",
              "       'yes', 'yes', 'yes', 'no'], dtype=object)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df[:,-1]\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8lAjCdxiFQD"
      },
      "source": [
        "5. Tính xem có bao nhiêu loại nhãn và số lần xuất hiện."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvRlaKn2kV7w",
        "outputId": "345b759b-28b1-4e48-cd0c-7173d9babca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['no', 'yes'], dtype=object), array([5, 9]))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rs_class, counts = np.unique(y,return_counts=True)\n",
        "rs_class, counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAOM6w6KiQ2T"
      },
      "source": [
        "6. Viết code chạy vòng lặp ngay trên mảng và tính tổng\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBENqHigcKY5",
        "outputId": "2d214614-0e7b-4add-bf13-cee6a5cf975a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum([i for i in counts])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNdg_hfWiXUT"
      },
      "source": [
        "7. Viết hàm tính Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK9vGY74RpUs",
        "outputId": "da931d79-2c02-4df5-9463-1c49f094e6d8"
      },
      "outputs": [],
      "source": [
        "def entropy(data):\n",
        "    cl, counts = np.unique(data,return_counts=True)\n",
        "    rs = -  counts/np.sum(counts) * np.log2(counts/np.sum(counts))\n",
        "    return np.sum(rs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.584962500721156"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = np.array([\"no\", \"yes\", 'not given'])\n",
        "entropy(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke9scekcii-7"
      },
      "source": [
        "8. Lọc dữ liệu có thời tiết bằng nằng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jzs8reCskV70"
      },
      "outputs": [],
      "source": [
        "sunny_df = df[df[:,0] == 'sunny']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f66xoxh8isMs"
      },
      "source": [
        "9. Lấy nhãn của dữ liệu có thời tiết là nắng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqiIBDHWkV70",
        "outputId": "442fc0d7-7b80-4962-f81b-c549f07d45d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['no', 'no', 'no', 'yes', 'yes'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = sunny_df[:,-1]\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v09nwOHVi88C"
      },
      "source": [
        "10. Viết hàm tính Gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNzT4CLfkV72",
        "outputId": "b08d1ce0-83be-441a-e677-c150f9bd670a"
      },
      "outputs": [],
      "source": [
        "#TÍnh GAIN =E(s)-W_E\n",
        "def infomation_gain(data,split_attribute_index,target_index=-1):\n",
        "    total_gain = entropy(data[:,target_index])\n",
        "    \n",
        "    val, counts = np.unique(data[:,split_attribute_index],return_counts=True)\n",
        "    # print(val,counts)\n",
        "    s = sum([(j/np.sum(counts)) *entropy(data[data[:,split_attribute_index] == i][:,-1]) for i,j in zip(val,counts)])\n",
        "    return total_gain - s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.24674981977443933,\n",
              " 0.02922256565895487,\n",
              " 0.15183550136234159,\n",
              " 0.04812703040826949]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = np.arange(df.shape[1]-1)\n",
        "info_gain_list = [infomation_gain(data=df,split_attribute_index=feature,target_index=-1) for feature in features]\n",
        "info_gain_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>outlook</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sunny</td>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>weak</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sunny</td>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>strong</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>overcast</td>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>weak</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rainy</td>\n",
              "      <td>mild</td>\n",
              "      <td>high</td>\n",
              "      <td>weak</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rainy</td>\n",
              "      <td>cool</td>\n",
              "      <td>normal</td>\n",
              "      <td>weak</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    outlook temperature humidity    wind class\n",
              "0     sunny         hot     high    weak    no\n",
              "1     sunny         hot     high  strong    no\n",
              "2  overcast         hot     high    weak   yes\n",
              "3     rainy        mild     high    weak   yes\n",
              "4     rainy        cool   normal    weak   yes"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"weather1.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "RhTsIjfxkV72"
      },
      "outputs": [],
      "source": [
        "#Hàm đầy đủ\n",
        "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
        "    \"\"\"\n",
        "    Calculate the information gain of a dataset. This function takes three parameters:\n",
        "    1. data = The dataset for whose feature the IG should be calculated\n",
        "    2. split_attribute_name = the name of the feature for which the information gain should be calculated\n",
        "    3. target_name = the name of the target feature. The default for this example is \"class\"\n",
        "    \"\"\"\n",
        "    #Calculate the entropy of the total dataset\n",
        "    total_entropy = entropy(data[target_name])\n",
        "\n",
        "    ##Calculate the entropy of the dataset\n",
        "\n",
        "    #Calculate the values and the corresponding counts for the split attribute\n",
        "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
        "    print(vals,counts)\n",
        "    #Calculate the weighted entropy\n",
        "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
        "\n",
        "    #Calculate the information gain\n",
        "    Information_Gain = total_entropy - Weighted_Entropy\n",
        "    return Information_Gain\n",
        "\n",
        "###################\n",
        "\n",
        "###################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYOfUakjkV73",
        "outputId": "cafb92c0-18e1-496b-a72d-b7bb93ea511f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['outlook', 'temperature', 'humidity', 'wind'], dtype='object')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Xác định GAIN của cột nào là lớn nhất\n",
        "#lây ra các thuộc tinh của bảng loại cột nhãn\n",
        "features=data.columns[:-1]\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5beh-gM1kV73",
        "outputId": "501e44e2-06f9-44a9-b1c3-dddec9a0b4c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['overcast' 'rainy' 'sunny'] [4 5 5]\n",
            "['cool' 'hot' 'mild'] [4 4 6]\n",
            "['high' 'normal'] [7 7]\n",
            "['strong' 'weak'] [6 8]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.24674981977443933,\n",
              " 0.02922256565895487,\n",
              " 0.15183550136234159,\n",
              " 0.04812703040826949]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Tinh GAIN cho từng thuộc tính\n",
        "item_values = [InfoGain(data=data,split_attribute_name=feature) for feature in features]\n",
        "item_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZaI9kgzgkV74",
        "outputId": "41d1f8d0-f3fc-44cd-d160-fd9634daec8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'outlook'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Tim thuộc nào có GAIN lớn nhất\n",
        "index = np.argmax(item_values)\n",
        "best_feature = features[index]\n",
        "best_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5IFPAbklkV74"
      },
      "outputs": [],
      "source": [
        "#Đua thuộc tính được chọn vào cây\n",
        "tree = {best_feature:{}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLrb_tSMkV74",
        "outputId": "a1a91631-5448-4f3d-80c7-5c84273821e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['temperature', 'humidity', 'wind']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loại thuộc tính được chọn ra khỏi tập thuộc tinh\n",
        "features = [i for i in features if i != best_feature]\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NWVea7p7kV75"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ID3' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/hin03/Machine_Learning/MachineLearning1/Assigment_ID3.ipynb Cell 32\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hin03/Machine_Learning/MachineLearning1/Assigment_ID3.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sub_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mwhere(data[best_feature] \u001b[39m==\u001b[39m value)\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hin03/Machine_Learning/MachineLearning1/Assigment_ID3.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m#gọi đệ quy lại chính nó và truyền tập dữ liệu con vào\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hin03/Machine_Learning/MachineLearning1/Assigment_ID3.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m subtree \u001b[39m=\u001b[39m ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hin03/Machine_Learning/MachineLearning1/Assigment_ID3.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tree[best_feature][value] \u001b[39m=\u001b[39m subtree\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ID3' is not defined"
          ]
        }
      ],
      "source": [
        " #duyệt qua từng giá trị có trong thuộc tính được chọn VD: Thời tiết(Nắng, mưa và nhiều mây)\n",
        "for value in np.unique(data[best_feature]):\n",
        "        #Lấy ra từng tập dữ liệu theo từng giá trị của thuộc tính được chọn\n",
        "    sub_data = data.where(data[best_feature] == value).dropna()\n",
        "        #gọi đệ quy lại chính nó và truyền tập dữ liệu con vào\n",
        "    subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
        "    tree[best_feature][value] = subtree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdbmvmcTkV75"
      },
      "outputs": [],
      "source": [
        "#Điều kiện dùng\n",
        "#Nếu tập dữ liệu con có cùng một lớp thì dùng.\n",
        " if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "        return np.unique(data[target_attribute_name])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs8sjwbRkV76"
      },
      "outputs": [],
      "source": [
        "#chuong trinh hoan chinh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from pprint import pprint\n",
        "\n",
        "def entropy(target_col):\n",
        "    \"\"\"\n",
        "    Calculate the entropy of a dataset.\n",
        "    The only parameter of this function is the target_col parameter which specifies the target column\n",
        "    \"\"\"\n",
        "    elements,counts = np.unique(target_col,return_counts = True)\n",
        "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
        "    return entropy\n",
        "\n",
        "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
        "    \"\"\"\n",
        "    Calculate the information gain of a dataset. This function takes three parameters:\n",
        "    1. data = The dataset for whose feature the IG should be calculated\n",
        "    2. split_attribute_name = the name of the feature for which the information gain should be calculated\n",
        "    3. target_name = the name of the target feature. The default for this example is \"class\"\n",
        "    \"\"\"\n",
        "    #Calculate the entropy of the total dataset\n",
        "    total_entropy = entropy(data[target_name])\n",
        "\n",
        "    ##Calculate the entropy of the dataset\n",
        "\n",
        "    #Calculate the values and the corresponding counts for the split attribute\n",
        "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
        "\n",
        "    #Calculate the weighted entropy\n",
        "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
        "\n",
        "    #Calculate the information gain\n",
        "    Information_Gain = total_entropy - Weighted_Entropy\n",
        "    return Information_Gain\n",
        "\n",
        "###################\n",
        "\n",
        "###################\n",
        "def ID3(data,originaldata,features,target_attribute_name=\"class\",parent_node_class = None):\n",
        "    \"\"\"\n",
        "    ID3 Algorithm: This function takes five paramters:\n",
        "    1. data = the data for which the ID3 algorithm should be run --> In the first run this equals the total dataset\n",
        "\n",
        "    2. originaldata = This is the original dataset needed to calculate the mode target feature value of the original dataset\n",
        "    in the case the dataset delivered by the first parameter is empty\n",
        "\n",
        "    3. features = the feature space of the dataset . This is needed for the recursive call since during the tree growing process\n",
        "    we have to remove features from our dataset --> Splitting at each node\n",
        "\n",
        "    4. target_attribute_name = the name of the target attribute\n",
        "\n",
        "    5. parent_node_class = This is the value or class of the mode target feature value of the parent node for a specific node. This is\n",
        "    also needed for the recursive call since if the splitting leads to a situation that there are no more features left in the feature\n",
        "    space, we want to return the mode target feature value of the direct parent node.\n",
        "    \"\"\"\n",
        "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#\n",
        "\n",
        "    #If all target_values have the same value, return this value\n",
        "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "        return np.unique(data[target_attribute_name])[0]\n",
        "\n",
        "    #If the dataset is empty, return the mode target feature value in the original dataset\n",
        "    elif len(data)==0:\n",
        "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
        "\n",
        "    #If the feature space is empty, return the mode target feature value of the direct parent node --> Note that\n",
        "    #the direct parent node is that node which has called the current run of the ID3 algorithm and hence\n",
        "    #the mode target feature value is stored in the parent_node_class variable.\n",
        "\n",
        "    elif len(features) ==0:\n",
        "        return parent_node_class\n",
        "\n",
        "    #If none of the above holds true, grow the tree!\n",
        "\n",
        "    else:\n",
        "        #Set the default value for this node --> The mode target feature value of the current node\n",
        "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
        "\n",
        "        #Select the feature which best splits the dataset\n",
        "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
        "        best_feature_index = np.argmax(item_values)\n",
        "        best_feature = features[best_feature_index]\n",
        "\n",
        "        #Create the tree structure. The root gets the name of the feature (best_feature) with the maximum information\n",
        "        #gain in the first run\n",
        "        tree = {best_feature:{}}\n",
        "\n",
        "\n",
        "        #Remove the feature with the best inforamtion gain from the feature space\n",
        "        features = [i for i in features if i != best_feature]\n",
        "\n",
        "        #Grow a branch under the root node for each possible value of the root node feature\n",
        "\n",
        "        for value in np.unique(data[best_feature]):\n",
        "           # value = value\n",
        "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets\n",
        "            sub_data = data.where(data[best_feature] == value).dropna()\n",
        "\n",
        "            #Call the ID3 algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\n",
        "            subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
        "\n",
        "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "        return(tree)\n",
        "\n",
        "###################\n",
        "\n",
        "###################\n",
        "#Hàm dự đoán\n",
        "#Dữ liệu dự đoán là\n",
        "def predict(query,tree,default = 1):\n",
        "\n",
        "    #1.\n",
        "    for key in list(query.keys()):\n",
        "        if key in list(tree.keys()):\n",
        "            #2.\n",
        "            try:\n",
        "                result = tree[key][query[key]]\n",
        "            except:\n",
        "                return default\n",
        "\n",
        "            #3.\n",
        "            result = tree[key][query[key]]\n",
        "            #4.\n",
        "            if isinstance(result,dict):\n",
        "                return predict(query,result)\n",
        "\n",
        "            else:\n",
        "                return result\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Check the accuracy of our prediction.\n",
        "The train_test_split function takes the dataset as parameter which should be divided into\n",
        "a training and a testing set. The test function takes two parameters, which are the testing data as well as the tree model.\n",
        "\"\"\"\n",
        "###################\n",
        "\n",
        "###################\n",
        "def train_test_split(dataset):\n",
        "    training_data = dataset.iloc[:80].reset_index(drop=True)#We drop the index respectively relabel the index\n",
        "    #starting form 0, because we do not want to run into errors regarding the row labels / indexes\n",
        "    testing_data = dataset.iloc[80:].reset_index(drop=True)\n",
        "    return training_data,testing_data\n",
        "#dataset=dataset.drop('animal_name',axis=1)\n",
        "def test(data,tree):\n",
        "    #Create new query instances by simply removing the target feature column from the original dataset and\n",
        "    #convert it to a dictionary\n",
        "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")\n",
        "\n",
        "    #Create a empty DataFrame in whose columns the prediction of the tree are stored\n",
        "    predicted = pd.DataFrame(columns=[\"predicted\"])\n",
        "\n",
        "    #Calculate the prediction accuracy\n",
        "    for i in range(len(data)):\n",
        "        predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0)\n",
        "    print('The prediction accuracy is: ',(np.sum(predicted[\"predicted\"] == data[\"class\"])/len(data))*100,'%')\n",
        "\n",
        "    \"\"\"\n",
        "Train the tree, Print the tree and predict the accuracy\n",
        "\"\"\"\n",
        "#dataset=pd.read_csv(\"./resources/weather_tv.csv\")\n",
        "#training_data=dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGRbMpdFkV78",
        "outputId": "2fcca422-ca2c-4e2c-ea60-688ef994a137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'outlook': {'overcast': 'yes',\n",
            "             'rainy': {'wind': {'strong': 'no', 'weak': 'yes'}},\n",
            "             'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n",
            "The prediction accuracy is:  100.0 %\n"
          ]
        }
      ],
      "source": [
        "#chạy thử trên bộ dữ liệu weather\n",
        "dataset=pd.read_csv(\"weather1.csv\")\n",
        "#các bạn chú ý: bộ dữ liệu này chi có 14 dóng, chúng ta cho bộ train =test=dataset\n",
        "training_data=testing_data=dataset\n",
        "tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
        "pprint(tree)\n",
        "test(testing_data,tree)\n",
        "#Kết quả chạy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJrDSxGSkV78",
        "outputId": "7ea8a411-d33d-4eb7-c8c5-844c1d2c234a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'legs': {0: {'fins': {0.0: {'toothed': {0.0: 7.0, 1.0: 3.0}},\n",
            "                       1.0: {'eggs': {0.0: 1.0, 1.0: 4.0}}}},\n",
            "          2: {'hair': {0.0: 2.0, 1.0: 1.0}},\n",
            "          4: {'hair': {0.0: {'toothed': {0.0: 7.0, 1.0: 5.0}}, 1.0: 1.0}},\n",
            "          6: {'aquatic': {0.0: 6.0, 1.0: 7.0}},\n",
            "          8: 7.0}}\n",
            "The prediction accuracy is:  85.71428571428571 %\n"
          ]
        }
      ],
      "source": [
        "#chạy thử trên bộ dữ liệu zoo\n",
        "dataset=pd.read_csv(\"./resources/zoo.csv\")\n",
        "#xoa cột tên con vật\n",
        "dataset=dataset.drop('animal_name',axis=1)\n",
        "\n",
        "training_data = train_test_split(dataset)[0]\n",
        "testing_data = train_test_split(dataset)[1]\n",
        "#training_data,testing_data=train_test_split(dataset)\n",
        "\n",
        "#y=np.array([y])\n",
        "tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
        "pprint(tree)\n",
        "test(testing_data,tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlOv2N-AkV79",
        "outputId": "646c1abd-bfe4-42ac-a21c-22117b7bd8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Student': {'no': {'Age': {'31..40': 'yes',\n",
            "                            '31…40': 'yes',\n",
            "                            '<=30': 'no',\n",
            "                            '>40': {'Credit_rating': {'excellent': 'no',\n",
            "                                                      'fair': {'Income': {'medium': 'no'}}}}}},\n",
            "             'yes': 'yes'}}\n",
            "The prediction accuracy is:  92.85714285714286 %\n"
          ]
        }
      ],
      "source": [
        "dataset=pd.read_csv(\"./resources/cumputer1.csv\")\n",
        "training_data=testing_data=dataset\n",
        "tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
        "pprint(tree)\n",
        "test(testing_data,tree)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
